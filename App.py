import io
import time
import requests
import streamlit as st
from PIL import Image

st.set_page_config(page_title="äººåƒèªªè©±å½±ç‰‡ç”Ÿæˆå™¨", page_icon="ğŸ¬", layout="centered")

st.title("ğŸ¬ äººåƒèªªè©±å½±ç‰‡ç”Ÿæˆå™¨")
st.caption("ä¸Šå‚³äººåƒç…§ç‰‡ï¼Œè¼¸å…¥æ–‡å­—ï¼Œç”Ÿæˆä¸€æ®µäººåƒèªªè©±å½±ç‰‡ã€‚")

# ä½¿ç”¨è€…è¼¸å…¥
img_url = st.text_input("è¼¸å…¥äººåƒåœ–ç‰‡ URL (å¿…é ˆå¯å…¬é–‹å­˜å–)")
text = st.text_area("è¼¸å…¥è¦èªªçš„æ–‡å­—", placeholder="ä¾‹å¦‚ï¼šå¤§å®¶å¥½ï¼Œæ­¡è¿ä¾†åˆ°æˆ‘çš„é »é“ã€‚", height=120)

# èªéŸ³é¸æ“‡ (Azure æä¾›å¤šç¨® voice)
voice = st.selectbox("é¸æ“‡èªéŸ³é¢¨æ ¼", ["zh-TW-HsiaoYuNeural", "zh-TW-YatingNeural", "en-US-JennyNeural"])

can_run = img_url.strip() != "" and (text is not None and text.strip() != "")

# Secrets
AZURE_SPEECH_KEY = st.secrets.get("AZURE_SPEECH_KEY")
AZURE_SPEECH_REGION = st.secrets.get("AZURE_SPEECH_REGION", "japaneast")
DID_API_KEY = st.secrets.get("DID_API_KEY")

if not AZURE_SPEECH_KEY or not DID_API_KEY:
    st.error("è«‹å…ˆåœ¨ Streamlit Secrets è¨­å®š AZURE_SPEECH_KEYã€AZURE_SPEECH_REGION å’Œ DID_API_KEYï¼")
    st.stop()

def generate_audio_azure(text: str, voice: str = "zh-TW-HsiaoYuNeural") -> str:
    """ä½¿ç”¨ Azure Speech Service ç”ŸæˆèªéŸ³ï¼Œä¸¦å›å‚³å¯å­˜å–çš„ URL"""
    endpoint = f"https://{AZURE_SPEECH_REGION}.tts.speech.microsoft.com/cognitiveservices/v1"
    headers = {
        "Ocp-Apim-Subscription-Key": AZURE_SPEECH_KEY,
        "Content-Type": "application/ssml+xml",
        "X-Microsoft-OutputFormat": "riff-24khz-16bit-mono-pcm"
    }
    ssml = f"""
    <speak version='1.0' xml:lang='zh-TW'>
      <voice name='{voice}'>
        {text}
      </voice>
    </speak>
    """
    resp = requests.post(endpoint, headers=headers, data=ssml.encode("utf-8"))
    resp.raise_for_status()

    # âš ï¸ é€™è£¡éœ€è¦æŠŠéŸ³è¨Šæª”ä¸Šå‚³åˆ°ä¸€å€‹å¯å…¬é–‹å­˜å–çš„ URL
    # ç¯„ä¾‹ï¼šå…ˆå­˜åˆ°æœ¬åœ°ï¼Œå†æ‰‹å‹•ä¸Šå‚³åˆ° GitHub/S3/Google Drive
    with open("speech.wav", "wb") as f:
        f.write(resp.content)

    st.audio(resp.content, format="audio/wav")
    st.warning("è«‹å°‡ speech.wav ä¸Šå‚³åˆ°é›²ç«¯ä¸¦å–å¾—å…¬é–‹ URLï¼Œç„¶å¾Œè²¼åˆ°ä¸‹æ–¹æ¬„ä½ã€‚")
    return None  # æš«æ™‚ä¸å›å‚³ URLï¼Œéœ€äººå·¥ä¸Šå‚³

def generate_talking_video(image_url: str, audio_url: str) -> str:
    """å‘¼å« D-ID API ç”Ÿæˆäººåƒèªªè©±å½±ç‰‡"""
    url = "https://api.d-id.com/talks"
    headers = {"Authorization": f"Bearer {DID_API_KEY}", "Content-Type": "application/json"}
    payload = {
        "source_url": image_url,
        "script": {
            "type": "audio",
            "audio_url": audio_url
        }
    }
    resp = requests.post(url, headers=headers, json=payload)
    resp.raise_for_status()
    job_id = resp.json().get("id")

    status_url = f"https://api.d-id.com/talks/{job_id}"
    progress_bar = st.progress(0)

    for i in range(60):
        status_resp = requests.get(status_url, headers=headers)
        status_resp.raise_for_status()
        status_json = status_resp.json()
        state = status_json.get("status")
        progress_bar.progress(int((i+1)/60*100))
        if state == "done":
            return status_json.get("result_url")
        elif state == "error":
            raise RuntimeError(status_json.get("error", "ç”Ÿæˆå¤±æ•—"))
        time.sleep(2)

    raise TimeoutError("ç”Ÿæˆå½±ç‰‡é€¾æ™‚")

if st.button("ç”Ÿæˆå½±ç‰‡", type="primary", disabled=not can_run):
    try:
        with st.spinner("æ­£åœ¨ç”ŸæˆèªéŸ³..."):
            generate_audio_azure(text.strip(), voice=voice)

        audio_url = st.text_input("è«‹è¼¸å…¥å‰›å‰›ä¸Šå‚³çš„ speech.wav å…¬é–‹ URL")
        if audio_url.strip() != "":
            with st.spinner("æ­£åœ¨ç”Ÿæˆå½±ç‰‡..."):
                video_url = generate_talking_video(img_url.strip(), audio_url.strip())
            st.success("å½±ç‰‡ç”Ÿæˆå®Œæˆï¼")
            st.video(video_url)
            st.markdown(f"[ä¸‹è¼‰å½±ç‰‡]({video_url})")

    except Exception as e:
        st.error(f"éŒ¯èª¤ï¼š{e}")
        st.stop()

st.markdown("---")
st.markdown("æç¤ºï¼šè«‹ä½¿ç”¨æ­£é¢ã€å…‰ç·šå……è¶³çš„äººåƒç…§ç‰‡ï¼Œæ•ˆæœæœ€ä½³ã€‚")        "X-Microsoft-OutputFormat": "riff-24khz-16bit-mono-pcm"
    }
    ssml = f"""
    <speak version='1.0' xml:lang='zh-TW'>
      <voice name='{voice}'>
        {text}
      </voice>
    </speak>
    """
    resp = requests.post(endpoint, headers=headers, data=ssml.encode("utf-8"))
    resp.raise_for_status()
    return resp.content

def generate_talking_video(image_bytes: bytes, audio_bytes: bytes) -> bytes:
    """å‘¼å« D-ID API ç”Ÿæˆäººåƒèªªè©±å½±ç‰‡"""
    url = f"{DID_API_BASE}/talks"
    headers = {"Authorization": f"Bearer {DID_API_KEY}"}
    files = {
        "source_image": ("portrait.png", image_bytes, "image/png"),
        "audio": ("speech.wav", audio_bytes, "audio/wav"),
    }
    resp = requests.post(url, headers=headers, files=files, timeout=120)
    resp.raise_for_status()
    payload = resp.json()

    job_id = payload.get("id")
    status_url = f"{DID_API_BASE}/talks/{job_id}"

    progress_bar = st.progress(0)
    for i in range(60):
        status_resp = requests.get(status_url, headers=headers)
        status_resp.raise_for_status()
        status_json = status_resp.json()
        state = status_json.get("status")
        progress_bar.progress(int((i+1)/60*100))
        if state == "done":
            video_url = status_json.get("result_url")
            video_resp = requests.get(video_url)
            video_resp.raise_for_status()
            return video_resp.content
        elif state == "error":
            raise RuntimeError(status_json.get("error", "ç”Ÿæˆå¤±æ•—"))
        time.sleep(2)

    raise TimeoutError("ç”Ÿæˆå½±ç‰‡é€¾æ™‚")

def show_video_and_download(video_bytes: bytes, filename: str = "talking_photo.mp4"):
    st.video(video_bytes)
    st.download_button(
        label="ä¸‹è¼‰å½±ç‰‡",
        data=video_bytes,
        file_name=filename,
        mime="video/mp4",
        width="stretch"
    )

if st.button("ç”Ÿæˆå½±ç‰‡", type="primary", disabled=not can_run):
    try:
        image = Image.open(img_file).convert("RGB")
        st.image(image, caption="å·²ä¸Šå‚³äººåƒ", width="stretch")

        buf = io.BytesIO()
        image.save(buf, format="PNG")
        img_bytes = buf.getvalue()

        with st.spinner("æ­£åœ¨ç”ŸæˆèªéŸ³..."):
            audio_bytes = generate_audio_azure(text.strip(), voice=voice)

        st.audio(audio_bytes, format="audio/wav")

        with st.spinner("æ­£åœ¨ç”Ÿæˆå½±ç‰‡..."):
            video_bytes = generate_talking_video(img_bytes, audio_bytes)

        st.success("å½±ç‰‡ç”Ÿæˆå®Œæˆï¼")
        show_video_and_download(video_bytes)

    except Exception as e:
        st.error(f"éŒ¯èª¤ï¼š{e}")
        st.stop()

st.markdown("---")
st.markdown("æç¤ºï¼šè«‹ä½¿ç”¨æ­£é¢ã€å…‰ç·šå……è¶³çš„äººåƒç…§ç‰‡ï¼Œæ•ˆæœæœ€ä½³ã€‚")
