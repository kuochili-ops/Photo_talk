import io
import time
import requests
import streamlit as st
from PIL import Image

st.set_page_config(page_title="äººåƒèªªè©±å½±ç‰‡ç”Ÿæˆå™¨", page_icon="ðŸŽ¬", layout="centered")

st.title("ðŸŽ¬ äººåƒèªªè©±å½±ç‰‡ç”Ÿæˆå™¨")
st.caption("ä¸Šå‚³äººåƒç…§ç‰‡ï¼Œè¼¸å…¥æ–‡å­—ï¼Œç”Ÿæˆä¸€æ®µäººåƒèªªè©±å½±ç‰‡ã€‚")

# ä½¿ç”¨è€…è¼¸å…¥
img_file = st.file_uploader("ä¸Šå‚³äººåƒç…§ç‰‡ (JPG/PNG)", type=["jpg", "jpeg", "png"])
text = st.text_area("è¼¸å…¥è¦èªªçš„æ–‡å­—", placeholder="ä¾‹å¦‚ï¼šå¤§å®¶å¥½ï¼Œæ­¡è¿Žä¾†åˆ°æˆ‘çš„é »é“ã€‚", height=120)

can_run = img_file is not None and (text is not None and text.strip() != "")

# Secrets
DEEPGRAM_API_KEY = st.secrets.get("DEEPGRAM_API_KEY")
AZURE_SPEECH_KEY = st.secrets.get("AZURE_SPEECH_KEY")
AZURE_SPEECH_REGION = st.secrets.get("AZURE_SPEECH_REGION")
DID_API_KEY = st.secrets.get("DID_API_KEY")
DID_API_BASE = "https://api.d-id.com/v1"

def generate_audio_deepgram(text: str) -> bytes:
    """ä½¿ç”¨ Deepgram TTS (è‹±æ–‡)"""
    url = "https://api.deepgram.com/v1/speak?model=aura-2-thalia-en"
    headers = {
        "Authorization": f"Token {DEEPGRAM_API_KEY}",
        "Content-Type": "application/json"
    }
    data = {"text": text}
    resp = requests.post(url, headers=headers, json=data)
    resp.raise_for_status()
    return resp.content

def generate_audio_azure(text: str) -> bytes:
    """ä½¿ç”¨ Azure TTS (ä¸­æ–‡)"""
    url = f"https://{AZURE_SPEECH_REGION}.tts.speech.microsoft.com/cognitiveservices/v1"
    headers = {
        "Ocp-Apim-Subscription-Key": AZURE_SPEECH_KEY,
        "Content-Type": "application/ssml+xml",
        "X-Microsoft-OutputFormat": "riff-16khz-16bit-mono-pcm"
    }
    ssml = f"""
    <speak version='1.0' xml:lang='zh-TW'>
        <voice xml:lang='zh-TW' xml:gender='Female' name='zh-TW-HsiaoYuNeural'>
            {text}
        </voice>
    </speak>
    """
    resp = requests.post(url, headers=headers, data=ssml.encode("utf-8"))
    resp.raise_for_status()
    return resp.content

def generate_talking_video(image_bytes: bytes, audio_bytes: bytes) -> bytes:
    """å‘¼å« D-ID API ç”Ÿæˆäººåƒèªªè©±å½±ç‰‡"""
    url = f"{DID_API_BASE}/talks"
    headers = {"Authorization": f"Bearer {DID_API_KEY}"}
    files = {
        "source_image": ("portrait.png", image_bytes, "image/png"),
        "audio": ("speech.wav", audio_bytes, "audio/wav"),
    }
    resp = requests.post(url, headers=headers, files=files, timeout=120)
    resp.raise_for_status()
    payload = resp.json()

    job_id = payload.get("id")
    status_url = f"{DID_API_BASE}/talks/{job_id}"

    for _ in range(60):
        status_resp = requests.get(status_url, headers=headers)
        status_resp.raise_for_status()
        status_json = status_resp.json()
        state = status_json.get("status")
        if state == "done":
            video_url = status_json.get("result_url")
            video_resp = requests.get(video_url)
            video_resp.raise_for_status()
            return video_resp.content
        elif state == "error":
            raise RuntimeError(status_json.get("error", "ç”Ÿæˆå¤±æ•—"))
        time.sleep(2)

    raise TimeoutError("ç”Ÿæˆå½±ç‰‡é€¾æ™‚")

def show_video_and_download(video_bytes: bytes, filename: str = "talking_photo.mp4"):
    st.video(video_bytes)
    st.download_button(
        label="ä¸‹è¼‰å½±ç‰‡",
        data=video_bytes,
        file_name=filename,
        mime="video/mp4",
        use_container_width=True
    )

if st.button("ç”Ÿæˆå½±ç‰‡", type="primary", disabled=not can_run):
    try:
        image = Image.open(img_file).convert("RGB")
        st.image(image, caption="å·²ä¸Šå‚³äººåƒ", use_container_width=True)

        buf = io.BytesIO()
        image.save(buf, format="PNG")
        img_bytes = buf.getvalue()

        # åˆ¤æ–·èªžè¨€ï¼šä¸­æ–‡ç”¨ Azureï¼Œè‹±æ–‡ç”¨ Deepgram
        if any(ch >= u'\u4e00' and ch <= u'\u9fff' for ch in text):
            with st.spinner("æ­£åœ¨ç”Ÿæˆä¸­æ–‡èªžéŸ³..."):
                audio_bytes = generate_audio_azure(text.strip())
        else:
            with st.spinner("æ­£åœ¨ç”Ÿæˆè‹±æ–‡èªžéŸ³..."):
                audio_bytes = generate_audio_deepgram(text.strip())

        with st.spinner("æ­£åœ¨ç”Ÿæˆå½±ç‰‡..."):
            video_bytes = generate_talking_video(img_bytes, audio_bytes)

        st.success("å½±ç‰‡ç”Ÿæˆå®Œæˆï¼")
        show_video_and_download(video_bytes)

    except Exception as e:
        st.error(f"éŒ¯èª¤ï¼š{e}")
        st.stop()

st.markdown("---")
st.markdown("æç¤ºï¼šè«‹ä½¿ç”¨æ­£é¢ã€å…‰ç·šå……è¶³çš„äººåƒç…§ç‰‡ï¼Œæ•ˆæžœæœ€ä½³ã€‚")
